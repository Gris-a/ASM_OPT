# Оптимизация хеш-таблицы

В данном проекте была реализована хеш-таблица методом цепочек в целях тестирования различных хеш-функций и изучения ассемблерных оптимизаций.

Хеш-таблица была основана на том, что коллизии были разрешены путём объединения элементов с одним значением хеша в односвязный список. Чтобы вставить новый элемент в таблицу, нужно посчитать его хеш и затем пройтись по цепочке, попутно сравнивая все элементы списка с нашим, что занимает O(k) времени, где k - длина цепочки, поэтому нашей целью является получить хеш-функцию, дающую наименьшее число коллизий, то есть наиболее равномерное распределение, для анализа которого просчитывалась дисперсия случайной величины $L$ - длины цепочки $D[L] = \sum\frac{(L_{i} - L_{avg})^2}{N}$, где $L_{i}$ - длина цепи соответствующая $i$ позиции в таблице, $L_{avg}$ - получившееся среднее значение длины цепи, $N$ - размер таблицы.

Для тестирования были выбраны следующие хеш-функции:

- ConstHash    - константный 0
- CharHash     - первый символ строки
- StrLenHash   - длина строки
- CheckSumHash - контрольная сумма(сумма всех ASCII-кодов символов строки)
- RotLHash     - подсчёт хеша за счёт битового поворота влево
- RotRHash     - подсчёт хеша за счёт битового поворота вправо
- CRC32Hash    - подсчёт циклического избыточного кода

Хеш-функции тестировались на наборе [hash_functions_test](hash_functions_testing/data/hash_functions_test.txt)(200000 слов), затем строились графики зависимости длины цепочки от её номера в таблице и проводился анализ. Для тестирования хеш-функций размер таблицы брался примерно в 3 раза меньше размера данных. Далее была выбрана лучшая из полученных хеш-функций и хеш-таблица была оптимизирована на уровне ассемблера. Эти тесты запускались на данных из [hash_table_test8-31.txt](/hash_table_optimizations/data/hash_table_test8-31.txt)(150000 слов) при размерах таблицы в 1.5 раза больше числа слов.

## Установка и тестирование

Установка:

    git clone https://github.com/Gris-a/ASM_OPT.git
    cd ASM_OPT
    cd hash_functions_testing && make
    cd ../
    cd hash_table_optimizations && make

Запуск тестирования:

    .hash_functions_testing/scripts/runtests.bash
    .hash_table_optimizations/scripts/runtests.bash

После завершения программы результаты тестирования хеш-функций появятся в папке [results](/hash_functions_testing/data/results), результаты профилирования разных этапов оптимизации хеш-таблицы появятся в папке [prof_results](/hash_table_optimizations/data/prof_results). Последние могут быть просмотрены при помощи `Kcachegrind`.

## Тестирование хеш-функций

Далее будут подробно описаны используемые хеш-функции и анализ результатов их тестирования.

### ConstHash

Данная хеш-функция возвращает 0.

```C
size_t HashFuncConst(char *key, size_t mod)
{
    return 0;
}
```

При таком подходе становится очевидно, что таблица превращается в односвязный список, сводя на нет все преимущества хеширования, что подтверждают графики:
|                                    |                                     |
|:----------------------------------:|:-----------------------------------:|
|![img](/readme_assets/ConstHash.png)|![img](/readme_assets/1ConstHash.png)|

и полученная дисперсия $D = 610332.9$.

### CharHash

Данная хеш-функция возвращает первый символ строки.

```C
size_t HashFuncChar(char *key, size_t mod)
{
    return key[0] % mod;
}
```

Из графиков видно, что из-за ограничения количества возможных символов данная хеш функция не даёт хорошего распределения:
|                                   |                                    |
|:---------------------------------:|:----------------------------------:|
|![img](/readme_assets/CharHash.png)|![img](/readme_assets/1CharHash.png)|

что также подтверждается значением дисперсии, равным $D = 52581.1$.

### StrLenHash

Данная хеш-функция возвращает длину строки.

```C
size_t HashFuncStrLen(char *key, size_t mod)
{
    return strlen(key) % mod;
}
```

Как и со многими хеш-функциями до этого, очевидно значение ключей будет сильно ограничено, а так же вероятность коллизии очень высока, подтверждение можно увидеть на графике:
|                                     |                                      |
|:-----------------------------------:|:------------------------------------:|
|![img](/readme_assets/StrLenHash.png)|![img](/readme_assets/1StrLenHash.png)|

Десперсия составила $D = 59633.8$.

### CheckSumHash

Данная хеш-функция возвращает сумму всех ASCII-кодов символов строки.

```C
size_t HashFuncCheckSum(char *key, size_t mod)
{
    size_t hash = 0;
    for(char c = *key; c != '\0'; c = *(++key))
    {
        hash += c;
        hash %= mod;
    }
    return hash;
}
```

Сперва мы протестировали данную функцию при большом размере таблицы:
|                                       |                                        |
|:-------------------------------------:|:--------------------------------------:|
|![img](/readme_assets/CheckSumHash.png)|![img](/readme_assets/1CheckSumHash.png)|

Как видно из графика, результаты оказались плохими, так как в нашем датасете не было слов длины даже больше 30, что даёт самое большее возможное значение хеша в ascii('z') * 30 = 3660, в нашем случае вышло около 2000, но приблизив график была обнаружена возможность равномерного распределения ключей по ячейкам таблицы при достаточно малых размерах таблицы:

![img](/readme_assets/CheckSumHash(small).png)

Разброс оказался довольно большим ввиду большой загруженности таблицы, потому был проведён дополнительный тест, где количество ключей было меньше:

![img](/readme_assets/1CheckSumHash(small).png)

Уже получше, но в реальности лучше применять другие хеши, так как данная функция работает приемлемо только на маленьких таблицах, что замедлит работу при большом количестве данных.

Полученные дисперсии составили соответственно $709.3$, $7207.5$ и $2.9$.

### RotLHash

Данная хеш-функция итерирует по всем символам строки `c` операцию `hash = rol(hash) ^ c`.

```C
#define ROL64(num, shift) ((num) << shift) | ((num) >> (sizeof(uint64_t) * 8 - shift))

size_t HashFuncRotL(char *key, size_t mod)
{
    size_t hash = 0;
    while(*key != '\0')
    {
        hash = ROL64(hash, 1);
        hash ^= *(key++);
    }
    return hash % mod;
}
```

Что показалось интересным, компилятор даже без оптимизаций может увидеть что мой макрос выполняет именно операцию `rol` и заменяет его на ассемблерную инструкцию, что видно из godbolt-a:

![img](/readme_assets/godbolt_rol.png)

Данная хеш-функция оказалась намного эффективнее предыдущих, так как она осуществляет некоторое количество сдвигов, что позволяет получать довольно большие значения хеша, что ведёт к вероятности заполнения наибольшего числа ячеек таблицы:

![img](/readme_assets/RotLHash.png)

Начало таблицы оказалось наиболее загруженным, что может быть связано со свойствами функции.

Дисперсия составила $D = 28.7$.

### RotRHash

Данная хеш-функция итерирует по всем символам строки `c` операцию `hash = ror(hash) ^ c`.

```C
#define ROR64(num, shift) ((num) >> shift) | ((num) << (sizeof(uint64_t) * 8 - shift))

size_t HashFuncRotR(char *key, size_t mod)
{
    size_t hash = 0;
    while(*key != '\0')
    {
        hash = ROR64(hash, 1);
        hash ^= *(key++);
    }
    return hash % mod;
}
```

Вопреки ожиданиям, данная хеш-функция показала себя не очень хорошо, по сравнению с RotLHash:

![img](/readme_assets/RotRHash.png)

Это может быть связано с тем, что при сдвиге в право при относительно коротких строках заполняются только старшие биты, поэтому взятие хеша по модулю размера таблицы работает не так как ожидалось.

Дисперсия составила $D = 60.3$.

### CRC32

Данная хеш-функция основана на представлении ключа в виде многочлена над $F_2$ и взятии остатка при делении его на какой-то подобранный многочлен, подробная реализация деления многочленов описана [здесь](https://ru.m.wikipedia.org/wiki/CRC32).

```C
size_t HashFuncCRC32(char *key, size_t mod)
{
    uint64_t crc = 0;

    size_t key_len    = strlen(key);
    size_t first_take = key_len % 4;

    for(size_t i = 0; i < first_take; i++)
    {
        crc <<= 8;
        crc |= key[i];
    }
    crc <<= 32;

    for(size_t i = first_take; i < key_len; i += 4)
    {
        crc |= (uint64_t)(*(uint32_t *)(key + i));

        for(size_t j = 0; j < 32; j++)
        {
            if(crc & ((uint64_t)1 << 63))
            {
                crc <<= 1;
                crc  ^= ((uint64_t)0x04C11DB7 << 32);
            }
            else crc <<= 1;
        }
    }

    return (size_t)((crc >> 32) % mod);
}
```

Данная функция оказалась наиболее успешной, так как полученная дисперсия составила $D = 3.4$, так же подтверждение можно увидеть из графика:

![img](/readme_assets/CRC32Hash.png)

### Анализ

Таблица с результатами:

| Хеш-функция | Дисперсия |
|:-----------:|----------:|
|Constant     |  610332.9 |
|StrLen       |   59633.8 |
|FirstChar    |   52581.1 |
|CheckSum     |     709.3 |
|RotR         |      60.3 |
|RotL         |      28.7 |
|CRC32        |       3.4 |

CRC32 показала себя лучше других, к тому же она имеет большой потенциал к оптимизации, поэтому в дальнейшем была выбрана именно она.

## Оптимизирование хеш-таблицы

Для оптимизации хеш-таблицы таблица заполнялась набором из $150 \cdot 10^3$ слов, а затем операция вставки повторялась ещё 99 раз. Это делалось ввиду того, что все хеш-функции имеют схожий цикл, итерирующий элементы списка коллизии, поэтому можно было рассматривать только одну функцию `HashTableInsert`. Размер таблицы брался $2^{18}$.

Запускать тесты будем по 3 раза и измерять среднее количество тактов, измеренное при помощи команды `rdtsc`, флаги компилятора при запуске: `-O1 -mavx2`.

Для оптимизации нужно сначала определить, где программа может вести себя неэффективно, для этого использовалась программа `valgrind`, а точнее профилировщик `callgrind`. Для начала профилирования нужно исползуется команда `valgrind --tool=callgrind --callgrind-out-file=<out file>   --toggle-collect=HashTableInsert <test.out>`, таким образом мы получим сведения о вызовах функции `HashTableInsert` при исполнении программы `<test.out>` и сохраним их в файле `<out file>`, который можно просмотреть с помощью `kcahcegrind`.

Для начала измерим скорость тестирования без оптимизаций.

| $t_1$       | $t_2$       | $t_3$       | $t_{avg}$               |
|:-----------:|:-----------:|:-----------:|:-----------------------:|
| 86486763590 | 86398959414 | 86452134454 | $(8645 ± 3) \cdot 10^7$ |

### Оптимизация 1 этап

При запуске профилировщика получили следующее:

![img](/readme_assets/prof_no_opt.png)

Как видно, ключевым недостатком является реализация хеш-функции, поэтому для начала оптимизируем её.

Данная хеш-функция была выбрана не только за её хорошее распределение, а так же потому что она может быть просчитана процессором при помощи ассемблерной инструкции `crc32`. Воспользовавшись этим и переписав функцию на ассемблере в файле [crc32.asm](/hash_table_optimizations/source/crc32.asm).

Таким образом получившееся время:

| $t_1$       | $t_2$       | $t_3$       | $t_{avg}$               |
|:-----------:|:-----------:|:-----------:|:-----------------------:|
| 25568977964 | 25487860616 | 25479451576 | $(2551 ± 4) \cdot 10^7$ |

### Оптимизация 2 этап

Снова запустим `valgrind` для поиска не эффективных мест. Получим следующие результаты:

![img](/readme_assets/prof_opt1.png)

Функция, обозначенная как `0x00000000004016d0` это реализованный на ассемблере CRC32, как видно теперь он занимает третью строчку рейтинга. На верхнем месте расположена сама функция вставки, которую оптимизировать не удалось, так как там происходит итерация списка коллизии в цикле, так что конкретно на ассемблере ускорить сильно не удастся, мы лишь усложним код. В конце рейтинга расположены вызовы выделения динамической памяти, которые к сожалению тоже сложно оптимизировать. поэтому нам остается только посмотреть на оптимизации функций `strcmp` и `strlen`, как будет видно дальше оптимизировать `strlen` не придётся, так как она вызывается из под хеш функции, которая претерпит некоторые изменения. Значит остановимся на `strcmp`.

Очевидно, что `strcmp`, являясь функцией стандартной библиотеки, уже оптимизирована до предела для произвольных строк. Но что если бы строки имели одинаковую длину? Если воспользоваться этим и установить строкам длину 32 байта, то пожертвовав памятью мы можем получить ощутимый прирост скорости, так как такой набор строк можно будет сравнивать с помощью SIMD инструкций без затрат на измерение длины, итерирования по кускам нужной длины и т. п. что занимало бы большую часть времени. Поэтому напишем свою функцию сравнения 32-байтовых строк:

```C
static inline int str_compare(const char *s1, const char *s2)
{
    __m256i mm_s1 = _mm256_loadu_si256((__m256i *)s1);
    __m256i mm_s2 = _mm256_loadu_si256((__m256i *)s2);
    return _mm256_testc_si256(mm_s1, mm_s2);
}
```

Также из-за такого предположения можно переписать в более эффективной форме хеш-функцию:

```C
size_t CRC32(char *key, size_t mod)
{
    size_t crc = 0;
    asm
    (
        ".intel_syntax noprefix\n\t"
        "xor eax, eax\n\t"
        "crc32 rax, qword ptr [%1 +  0]\n\t"
        "crc32 rax, qword ptr [%1 +  8]\n\t"
        "crc32 rax, qword ptr [%1 + 16]\n\t"
        "crc32 rax, qword ptr [%1 + 24]\n\t"
        "dec %2\n\t"
        "and rax, %2\n\t"
        ".att_syntax prefix\n\t"
        : "=a"(crc)
        : "D"(key), "S"(mod)
    );

    return crc;
}
```

Стоит отметить, что ограничение в 32 байта не случайно. Действительно, во-первых обработка именно 32-байтовых строк будет наиболее эффективной, что видно по коду сверху. К тому же большинство реальных слов не превосходят длины в 32 символа, так что если понадобится, можно сделать дополнительную таблицу для длинных слов.

Таким образом получившееся время:

| $t_1$       | $t_2$       | $t_3$       | $t_{avg}$               |
|:-----------:|:-----------:|:-----------:|:-----------------------:|
| 18205353422 | 18197857742 | 18165972051 | $(1819 ± 2) \cdot 10^7$ |

Общие результаты представлены в таблице:

| Оптимизация | время                   | ускорение (абсолютное) | ускорение (относительное) |
|:-----------:|:-----------------------:|:----------------------:|:-------------------------:|
| no opt      | $(8645 ± 3) \cdot 10^7$ | 1.000                  | 1.000                     |
| opt  1      | $(2551 ± 4) \cdot 10^7$ | 3.389 ± 0.006          | 3.389 ± 0.006             |
| opt  2      | $(1819 ± 2) \cdot 10^7$ | 4.753 ± 0.007          | 1.402 ± 0.004             |

Таким образом общее ускорение составило около 4.75.

### Анализ

Мы использовали для оптимизации ассемблерные инструкции, а как известно языки более высокого уровня разработаны как раз из-за их лучшей читаемости, то есть наши оптимизации затрудняют чтение кода. Оценим самый быстрый полученный вариант программы и изначальный при помощи коэффициента $α = 100 \% \cdot \frac{T_{old}}{T_{new}} * N^{-1}$, где Ν - количество строк, написанных на ассемблере. В нашем случае α = $33.95 \% ± 0.05 \%$. Таким образом можно сделать вывод, что ассемблерные оптимизации программы оказались довольно удачными.

## Вывод

Таким образом, можно отметить, что выбор хеш-функции может сильно влиять на скорость работы таблицы, превращая операции, которые могли бы работать за O(1) в O(n), что даёт невероятный прирост скорости при большом размере таблицы. По поводу ассемблерных оптимизаций стоит отметить, что с ними стоит быть аккуратным, так как они могут привязать к архитектуре и усложняют код, но могут дать большой прирост скорости, так как компилятор не может предвидеть все возможные исходы и остаётся педантичным. К тому же он не сможет применить оптимизацию скорости за счёт увеличения объёма потребляемой памяти так, как это было сделано в данной работе.